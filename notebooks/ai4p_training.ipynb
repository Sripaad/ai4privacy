{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f04c7bb-f80a-47ad-a655-69f396233278",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import random\n",
    "import itertools\n",
    "import collections\n",
    "import datasets\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer, DataCollatorForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52de6dea-f7ca-4851-8e8d-8bac1e27fb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59cd8e2a-15f8-446c-acc0-38f7ec29db9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"distilbert-base-multilingual-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.model_max_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d974bf8e-286e-4309-94e6-d82899d67ff4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['masked_text', 'unmasked_text', 'privacy_mask', 'span_labels', 'bio_labels', 'tokenised_text', 'language'],\n",
       "        num_rows: 209261\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = datasets.load_dataset(\"Isotonic/pii-masking-200k_distilbert-base-multilingual-cased\", token=\"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\")\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea950da0-442d-4878-a39b-b910ebb3472f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = train['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3f3b0dc-e33e-4653-8150-c16d006e1aa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>masked_text</th>\n",
       "      <th>unmasked_text</th>\n",
       "      <th>privacy_mask</th>\n",
       "      <th>span_labels</th>\n",
       "      <th>bio_labels</th>\n",
       "      <th>tokenised_text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our [ORDINALDIRECTION_1] campus is scheduled f...</td>\n",
       "      <td>Our Southwest campus is scheduled for a remode...</td>\n",
       "      <td>{'[ORDINALDIRECTION_1]': 'Southwest', '[IBAN_1...</td>\n",
       "      <td>[[0, 4, 'O'], [4, 13, 'ORDINALDIRECTION_1'], [...</td>\n",
       "      <td>[O, B-ORDINALDIRECTION, O, O, O, O, O, O, O, O...</td>\n",
       "      <td>[Our, Southwest, campus, is, scheduled, for, a...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Come parte dell'arbitrato, il tuo IP [IP_1] è ...</td>\n",
       "      <td>Come parte dell'arbitrato, il tuo IP 185.48.85...</td>\n",
       "      <td>{'[IP_1]': '185.48.85.30', '[MASKEDNUMBER_1]':...</td>\n",
       "      <td>[[0, 37, 'O'], [37, 49, 'IP_1'], [49, 103, 'O'...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-IP, I-IP, ...</td>\n",
       "      <td>[Come, parte, dell, ', ar, ##bit, ##rato, ,, i...</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Utilizzando il [USERAGENT_1] del tuo dispositi...</td>\n",
       "      <td>Utilizzando il Mozilla/5.0 (Windows; U; Window...</td>\n",
       "      <td>{'[USERAGENT_1]': 'Mozilla/5.0 (Windows; U; Wi...</td>\n",
       "      <td>[[0, 15, 'O'], [15, 128, 'USERAGENT_1'], [128,...</td>\n",
       "      <td>[O, O, O, O, O, B-USERAGENT, I-USERAGENT, I-US...</td>\n",
       "      <td>[Ut, ##ili, ##zza, ##ndo, il, Mozilla, /, 5, ....</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[AGE_1] [GENDER_1] offering chemistry tutoring...</td>\n",
       "      <td>67 Two-spirit offering chemistry tutoring, loc...</td>\n",
       "      <td>{'[AGE_1]': '67', '[GENDER_1]': 'Two-spirit', ...</td>\n",
       "      <td>[[0, 2, 'AGE_1'], [2, 3, 'O'], [3, 13, 'GENDER...</td>\n",
       "      <td>[B-AGE, B-GENDER, I-GENDER, I-GENDER, O, O, O,...</td>\n",
       "      <td>[67, Two, -, spirit, offering, chemistry, tuto...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dans les propositions de politique pour l'ense...</td>\n",
       "      <td>Dans les propositions de politique pour l'ense...</td>\n",
       "      <td>{'[SEX_1]': 'Female', '[EYECOLOR_1]': 'Blue', ...</td>\n",
       "      <td>[[0, 183, 'O'], [183, 189, 'SEX_1'], [189, 190...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[Dans, les, proposition, ##s, de, politique, p...</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209256</th>\n",
       "      <td>Sono uno/a studente/a [SEX_1] che sta cercando...</td>\n",
       "      <td>Sono uno/a studente/a Female che sta cercando ...</td>\n",
       "      <td>{'[SEX_1]': 'Female', '[MASKEDNUMBER_1]': '657...</td>\n",
       "      <td>[[0, 22, 'O'], [22, 28, 'SEX_1'], [28, 137, 'O...</td>\n",
       "      <td>[O, O, O, O, O, O, O, B-SEX, O, O, O, O, O, O,...</td>\n",
       "      <td>[Sono, uno, /, a, studente, /, a, Female, che,...</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209257</th>\n",
       "      <td>Vorrei cambiare l'orario della mia sessione in...</td>\n",
       "      <td>Vorrei cambiare l'orario della mia sessione in...</td>\n",
       "      <td>{'[ORDINALDIRECTION_1]': 'Northeast', '[PIN_1]...</td>\n",
       "      <td>[[0, 133, 'O'], [133, 142, 'ORDINALDIRECTION_1...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[Vor, ##rei, cambiar, ##e, l, ', ora, ##rio, d...</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209258</th>\n",
       "      <td>Patient âgé de [AGE_1] ans, Sexe : [SEX_1], or...</td>\n",
       "      <td>Patient âgé de 77 years old ans, Sexe : Male, ...</td>\n",
       "      <td>{'[AGE_1]': '77 years old', '[SEX_1]': 'Male',...</td>\n",
       "      <td>[[0, 15, 'O'], [15, 27, 'AGE_1'], [27, 40, 'O'...</td>\n",
       "      <td>[O, O, O, O, B-AGE, I-AGE, I-AGE, O, O, O, O, ...</td>\n",
       "      <td>[Pat, ##ient, âgé, de, 77, years, old, ans, ,,...</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209259</th>\n",
       "      <td>Bonjour, je suis [FIRSTNAME_1] du club environ...</td>\n",
       "      <td>Bonjour, je suis Lacy du club environnemental ...</td>\n",
       "      <td>{'[FIRSTNAME_1]': 'Lacy', '[CREDITCARDNUMBER_1...</td>\n",
       "      <td>[[0, 17, 'O'], [17, 21, 'FIRSTNAME_1'], [21, 1...</td>\n",
       "      <td>[O, O, O, O, O, O, B-FIRSTNAME, I-FIRSTNAME, O...</td>\n",
       "      <td>[Bon, ##jou, ##r, ,, je, suis, Lac, ##y, du, c...</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209260</th>\n",
       "      <td>[FIRSTNAME_1], pouvez-vous évaluer mon plan de...</td>\n",
       "      <td>Madelynn, pouvez-vous évaluer mon plan de prép...</td>\n",
       "      <td>{'[FIRSTNAME_1]': 'Madelynn', '[PASSWORD_1]': ...</td>\n",
       "      <td>[[0, 8, 'FIRSTNAME_1'], [8, 193, 'O'], [193, 2...</td>\n",
       "      <td>[B-FIRSTNAME, I-FIRSTNAME, I-FIRSTNAME, O, O, ...</td>\n",
       "      <td>[Made, ##lyn, ##n, ,, pou, ##vez, -, vous, év,...</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>209261 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              masked_text  \\\n",
       "0       Our [ORDINALDIRECTION_1] campus is scheduled f...   \n",
       "1       Come parte dell'arbitrato, il tuo IP [IP_1] è ...   \n",
       "2       Utilizzando il [USERAGENT_1] del tuo dispositi...   \n",
       "3       [AGE_1] [GENDER_1] offering chemistry tutoring...   \n",
       "4       Dans les propositions de politique pour l'ense...   \n",
       "...                                                   ...   \n",
       "209256  Sono uno/a studente/a [SEX_1] che sta cercando...   \n",
       "209257  Vorrei cambiare l'orario della mia sessione in...   \n",
       "209258  Patient âgé de [AGE_1] ans, Sexe : [SEX_1], or...   \n",
       "209259  Bonjour, je suis [FIRSTNAME_1] du club environ...   \n",
       "209260  [FIRSTNAME_1], pouvez-vous évaluer mon plan de...   \n",
       "\n",
       "                                            unmasked_text  \\\n",
       "0       Our Southwest campus is scheduled for a remode...   \n",
       "1       Come parte dell'arbitrato, il tuo IP 185.48.85...   \n",
       "2       Utilizzando il Mozilla/5.0 (Windows; U; Window...   \n",
       "3       67 Two-spirit offering chemistry tutoring, loc...   \n",
       "4       Dans les propositions de politique pour l'ense...   \n",
       "...                                                   ...   \n",
       "209256  Sono uno/a studente/a Female che sta cercando ...   \n",
       "209257  Vorrei cambiare l'orario della mia sessione in...   \n",
       "209258  Patient âgé de 77 years old ans, Sexe : Male, ...   \n",
       "209259  Bonjour, je suis Lacy du club environnemental ...   \n",
       "209260  Madelynn, pouvez-vous évaluer mon plan de prép...   \n",
       "\n",
       "                                             privacy_mask  \\\n",
       "0       {'[ORDINALDIRECTION_1]': 'Southwest', '[IBAN_1...   \n",
       "1       {'[IP_1]': '185.48.85.30', '[MASKEDNUMBER_1]':...   \n",
       "2       {'[USERAGENT_1]': 'Mozilla/5.0 (Windows; U; Wi...   \n",
       "3       {'[AGE_1]': '67', '[GENDER_1]': 'Two-spirit', ...   \n",
       "4       {'[SEX_1]': 'Female', '[EYECOLOR_1]': 'Blue', ...   \n",
       "...                                                   ...   \n",
       "209256  {'[SEX_1]': 'Female', '[MASKEDNUMBER_1]': '657...   \n",
       "209257  {'[ORDINALDIRECTION_1]': 'Northeast', '[PIN_1]...   \n",
       "209258  {'[AGE_1]': '77 years old', '[SEX_1]': 'Male',...   \n",
       "209259  {'[FIRSTNAME_1]': 'Lacy', '[CREDITCARDNUMBER_1...   \n",
       "209260  {'[FIRSTNAME_1]': 'Madelynn', '[PASSWORD_1]': ...   \n",
       "\n",
       "                                              span_labels  \\\n",
       "0       [[0, 4, 'O'], [4, 13, 'ORDINALDIRECTION_1'], [...   \n",
       "1       [[0, 37, 'O'], [37, 49, 'IP_1'], [49, 103, 'O'...   \n",
       "2       [[0, 15, 'O'], [15, 128, 'USERAGENT_1'], [128,...   \n",
       "3       [[0, 2, 'AGE_1'], [2, 3, 'O'], [3, 13, 'GENDER...   \n",
       "4       [[0, 183, 'O'], [183, 189, 'SEX_1'], [189, 190...   \n",
       "...                                                   ...   \n",
       "209256  [[0, 22, 'O'], [22, 28, 'SEX_1'], [28, 137, 'O...   \n",
       "209257  [[0, 133, 'O'], [133, 142, 'ORDINALDIRECTION_1...   \n",
       "209258  [[0, 15, 'O'], [15, 27, 'AGE_1'], [27, 40, 'O'...   \n",
       "209259  [[0, 17, 'O'], [17, 21, 'FIRSTNAME_1'], [21, 1...   \n",
       "209260  [[0, 8, 'FIRSTNAME_1'], [8, 193, 'O'], [193, 2...   \n",
       "\n",
       "                                               bio_labels  \\\n",
       "0       [O, B-ORDINALDIRECTION, O, O, O, O, O, O, O, O...   \n",
       "1       [O, O, O, O, O, O, O, O, O, O, O, B-IP, I-IP, ...   \n",
       "2       [O, O, O, O, O, B-USERAGENT, I-USERAGENT, I-US...   \n",
       "3       [B-AGE, B-GENDER, I-GENDER, I-GENDER, O, O, O,...   \n",
       "4       [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "...                                                   ...   \n",
       "209256  [O, O, O, O, O, O, O, B-SEX, O, O, O, O, O, O,...   \n",
       "209257  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "209258  [O, O, O, O, B-AGE, I-AGE, I-AGE, O, O, O, O, ...   \n",
       "209259  [O, O, O, O, O, O, B-FIRSTNAME, I-FIRSTNAME, O...   \n",
       "209260  [B-FIRSTNAME, I-FIRSTNAME, I-FIRSTNAME, O, O, ...   \n",
       "\n",
       "                                           tokenised_text language  \n",
       "0       [Our, Southwest, campus, is, scheduled, for, a...       en  \n",
       "1       [Come, parte, dell, ', ar, ##bit, ##rato, ,, i...       it  \n",
       "2       [Ut, ##ili, ##zza, ##ndo, il, Mozilla, /, 5, ....       it  \n",
       "3       [67, Two, -, spirit, offering, chemistry, tuto...       en  \n",
       "4       [Dans, les, proposition, ##s, de, politique, p...       fr  \n",
       "...                                                   ...      ...  \n",
       "209256  [Sono, uno, /, a, studente, /, a, Female, che,...       it  \n",
       "209257  [Vor, ##rei, cambiar, ##e, l, ', ora, ##rio, d...       it  \n",
       "209258  [Pat, ##ient, âgé, de, 77, years, old, ans, ,,...       fr  \n",
       "209259  [Bon, ##jou, ##r, ,, je, suis, Lac, ##y, du, c...       fr  \n",
       "209260  [Made, ##lyn, ##n, ,, pou, ##vez, -, vous, év,...       fr  \n",
       "\n",
       "[209261 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c184d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Our', 'Southwest', 'campus', 'is', 'scheduled', 'for', 'a', 're',\n",
       "       '##mo', '##dell', '##ing', 'session', '.', 'We', 'aim', 'to',\n",
       "       'make', 'the', 'environment', 'more', 'con', '##duc', '##ive',\n",
       "       'for', 'learning', '.', 'Dona', '##tions', 'can', 'be', 'made',\n",
       "       'through', 'PL', '##0', '##66', '##00', '##900', '##97', '##0',\n",
       "       '##90', '##100', '##200', '##9', '##35', '##57', '##7', '##2', '.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13b07173",
   "metadata": {},
   "outputs": [],
   "source": [
    "kp = len(tokenizer(list(tt[0]), is_split_into_words=True, truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c5e0e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4770cefa-a1b3-4c61-b224-d353ac01b4e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "037cf3cea43e456aa4fbb317292ff7f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/209261 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# remove more than 512\n",
    "tt = df.tokenised_text.tolist()\n",
    "tt_lens = [len(tokenizer(list(t), is_split_into_words=True, truncation=True, max_length=512)['input_ids']) for t in tqdm(tt)]\n",
    "df[['tt_lens']] = 0\n",
    "df.tt_lens = tt_lens\n",
    "df = df.loc[df.tt_lens <= 510].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b37ec40-2be2-4d0d-a273-0d6bc433d3e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nt = df.bio_labels.tolist()\n",
    "nt = list(itertools.chain.from_iterable(nt)) # merge the list of lists into one list\n",
    "nt = collections.Counter(nt) # Get count of each tag\n",
    "all_labels = list(nt.keys()) # get all unique tags(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f136e5f7-672e-46cd-9968-a0d4c4f64d4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "source_texts = df.unmasked_text.tolist()\n",
    "target_texts = df.masked_text.tolist()\n",
    "tokenized_texts = df.tokenised_text.tolist()\n",
    "ner_tags = df.bio_labels.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19e7b39c-1cc9-4e25-9700-aa9ce6c3fd93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "014d7576-4c49-47d1-aec3-19199981e606",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Our Southwest campus is scheduled for a remodelling session. We aim to make the environment more conducive for learning. Donations can be made through PL06600900970901002009355772.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "283387ee-e978-449d-9492-237b0eb2f957",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Our [ORDINALDIRECTION_1] campus is scheduled for a remodelling session. We aim to make the environment more conducive for learning. Donations can be made through [IBAN_1].'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ced38fcf-014d-4142-959a-048e5a1b8eac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Rap', 'Rap')\n",
      "('##pel', '##pel')\n",
      "('pour', 'pour')\n",
      "('collecte', 'collecte')\n",
      "('##r', '##r')\n",
      "('le', 'le')\n",
      "('pai', 'pai')\n",
      "('##ement', '##ement')\n",
      "('de', 'de')\n",
      "('la', 'la')\n",
      "('pro', 'pro')\n",
      "('##cha', '##cha')\n",
      "('##ine', '##ine')\n",
      "('sé', 'sé')\n",
      "('##ance', '##ance')\n",
      "('de', 'de')\n",
      "('Or', 'Or')\n",
      "('##ie', '##ie')\n",
      "('.', '.')\n",
      "('Con', 'Con')\n",
      "('##fir', '##fir')\n",
      "('##mez', '##mez')\n",
      "('son', 'son')\n",
      "('adresse', 'adresse')\n",
      "('de', 'de')\n",
      "('fact', 'fact')\n",
      "('##urat', '##urat')\n",
      "('##ion', '##ion')\n",
      "('A', 'A')\n",
      "('##pt', '##pt')\n",
      "('.', '.')\n",
      "('998', '998')\n",
      "(',', ',')\n",
      "('code', 'code')\n",
      "('postal', 'postal')\n",
      "('1825', '1825')\n",
      "('##6', '##6')\n",
      "('.', '.')\n",
      "('Elle', 'Elle')\n",
      "('pai', 'pai')\n",
      "('##e', '##e')\n",
      "('en', 'en')\n",
      "('Bit', 'Bit')\n",
      "('##co', '##co')\n",
      "('##in', '##in')\n",
      "(',', ',')\n",
      "('en', 'en')\n",
      "('##voy', '##voy')\n",
      "('##ez', '##ez')\n",
      "('la', 'la')\n",
      "('demande', 'demande')\n",
      "('à', 'à')\n",
      "('3', '3')\n",
      "('##SM', '##SM')\n",
      "('##a', '##a')\n",
      "('##M', '##M')\n",
      "('##1', '##1')\n",
      "('##ca', '##ca')\n",
      "('##4', '##4')\n",
      "('##eo', '##eo')\n",
      "('##3', '##3')\n",
      "('##99', '##99')\n",
      "('##f', '##f')\n",
      "('##C', '##C')\n",
      "('##N', '##N')\n",
      "('##f', '##f')\n",
      "('##p', '##p')\n",
      "('##j', '##j')\n",
      "('##w', '##w')\n",
      "('##k', '##k')\n",
      "('##5', '##5')\n",
      "('##tz', '##tz')\n",
      "('##Q', '##Q')\n",
      "('##2', '##2')\n",
      "('##C', '##C')\n",
      "('##9', '##9')\n",
      "('##Q', '##Q')\n",
      "('##ND', '##ND')\n",
      "('##E', '##E')\n",
      "('##mes', '##mes')\n",
      "('##7', '##7')\n",
      "('##F', '##F')\n",
      "('##1', '##1')\n",
      "('##m', '##m')\n",
      "('.', '.')\n"
     ]
    }
   ],
   "source": [
    "## checking if the tokens align\n",
    "i = random.randint(0, len(source_texts))\n",
    "x0 = tokenizer.convert_ids_to_tokens(tokenizer(source_texts[i])['input_ids'])\n",
    "x0.pop(0)  # CLS is not present in the dataset\n",
    "for t in zip(x0, tokenized_texts[i]):\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "442dcbb1-e25e-4e2e-bec9-0e4e7520487d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('O', 'Rap')\n",
      "('O', '##pel')\n",
      "('O', 'pour')\n",
      "('O', 'collecte')\n",
      "('O', '##r')\n",
      "('O', 'le')\n",
      "('O', 'pai')\n",
      "('O', '##ement')\n",
      "('O', 'de')\n",
      "('O', 'la')\n",
      "('O', 'pro')\n",
      "('O', '##cha')\n",
      "('O', '##ine')\n",
      "('O', 'sé')\n",
      "('O', '##ance')\n",
      "('O', 'de')\n",
      "('B-FIRSTNAME', 'Or')\n",
      "('I-FIRSTNAME', '##ie')\n",
      "('O', '.')\n",
      "('O', 'Con')\n",
      "('O', '##fir')\n",
      "('O', '##mez')\n",
      "('O', 'son')\n",
      "('O', 'adresse')\n",
      "('O', 'de')\n",
      "('O', 'fact')\n",
      "('O', '##urat')\n",
      "('O', '##ion')\n",
      "('B-SECONDARYADDRESS', 'A')\n",
      "('I-SECONDARYADDRESS', '##pt')\n",
      "('I-SECONDARYADDRESS', '.')\n",
      "('I-SECONDARYADDRESS', '998')\n",
      "('O', ',')\n",
      "('O', 'code')\n",
      "('O', 'postal')\n",
      "('B-ZIPCODE', '1825')\n",
      "('I-ZIPCODE', '##6')\n",
      "('O', '.')\n",
      "('O', 'Elle')\n",
      "('O', 'pai')\n",
      "('O', '##e')\n",
      "('O', 'en')\n",
      "('O', 'Bit')\n",
      "('O', '##co')\n",
      "('O', '##in')\n",
      "('O', ',')\n",
      "('O', 'en')\n",
      "('O', '##voy')\n",
      "('O', '##ez')\n",
      "('O', 'la')\n",
      "('O', 'demande')\n",
      "('O', 'à')\n",
      "('B-BITCOINADDRESS', '3')\n",
      "('I-BITCOINADDRESS', '##SM')\n",
      "('I-BITCOINADDRESS', '##a')\n",
      "('I-BITCOINADDRESS', '##M')\n",
      "('I-BITCOINADDRESS', '##1')\n",
      "('I-BITCOINADDRESS', '##ca')\n",
      "('I-BITCOINADDRESS', '##4')\n",
      "('I-BITCOINADDRESS', '##eo')\n",
      "('I-BITCOINADDRESS', '##3')\n",
      "('I-BITCOINADDRESS', '##99')\n",
      "('I-BITCOINADDRESS', '##f')\n",
      "('I-BITCOINADDRESS', '##C')\n",
      "('I-BITCOINADDRESS', '##N')\n",
      "('I-BITCOINADDRESS', '##f')\n",
      "('I-BITCOINADDRESS', '##p')\n",
      "('I-BITCOINADDRESS', '##j')\n",
      "('I-BITCOINADDRESS', '##w')\n",
      "('I-BITCOINADDRESS', '##k')\n",
      "('I-BITCOINADDRESS', '##5')\n",
      "('I-BITCOINADDRESS', '##tz')\n",
      "('I-BITCOINADDRESS', '##Q')\n",
      "('I-BITCOINADDRESS', '##2')\n",
      "('I-BITCOINADDRESS', '##C')\n",
      "('I-BITCOINADDRESS', '##9')\n",
      "('I-BITCOINADDRESS', '##Q')\n",
      "('I-BITCOINADDRESS', '##ND')\n",
      "('I-BITCOINADDRESS', '##E')\n",
      "('I-BITCOINADDRESS', '##mes')\n",
      "('I-BITCOINADDRESS', '##7')\n",
      "('I-BITCOINADDRESS', '##F')\n",
      "('I-BITCOINADDRESS', '##1')\n",
      "('I-BITCOINADDRESS', '##m')\n",
      "('O', '.')\n"
     ]
    }
   ],
   "source": [
    "# Checking if the tokens align with tags\n",
    "# i = random.randint(0, len(target_texts))\n",
    "for t in zip(ner_tags[i], tokenized_texts[i]):\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a3848bd-bac9-4816-a7cf-a98f6aef36c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'O': 0,\n",
       "  'B-ORDINALDIRECTION': 1,\n",
       "  'B-IBAN': 2,\n",
       "  'I-IBAN': 3,\n",
       "  'B-IP': 4,\n",
       "  'I-IP': 5,\n",
       "  'B-MASKEDNUMBER': 6,\n",
       "  'I-MASKEDNUMBER': 7,\n",
       "  'B-USERAGENT': 8,\n",
       "  'I-USERAGENT': 9,\n",
       "  'B-PIN': 10,\n",
       "  'I-PIN': 11,\n",
       "  'B-AGE': 12,\n",
       "  'B-GENDER': 13,\n",
       "  'I-GENDER': 14,\n",
       "  'B-ZIPCODE': 15,\n",
       "  'I-ZIPCODE': 16,\n",
       "  'B-SEX': 17,\n",
       "  'B-EYECOLOR': 18,\n",
       "  'B-HEIGHT': 19,\n",
       "  'I-HEIGHT': 20,\n",
       "  'B-FIRSTNAME': 21,\n",
       "  'I-FIRSTNAME': 22,\n",
       "  'B-SSN': 23,\n",
       "  'I-SSN': 24,\n",
       "  'B-DOB': 25,\n",
       "  'I-DOB': 26,\n",
       "  'B-USERNAME': 27,\n",
       "  'I-USERNAME': 28,\n",
       "  'B-PASSWORD': 29,\n",
       "  'I-PASSWORD': 30,\n",
       "  'B-STREET': 31,\n",
       "  'I-STREET': 32,\n",
       "  'B-SECONDARYADDRESS': 33,\n",
       "  'I-SECONDARYADDRESS': 34,\n",
       "  'B-COUNTY': 35,\n",
       "  'I-COUNTY': 36,\n",
       "  'B-STATE': 37,\n",
       "  'I-STATE': 38,\n",
       "  'B-PREFIX': 39,\n",
       "  'I-PREFIX': 40,\n",
       "  'B-LASTNAME': 41,\n",
       "  'I-LASTNAME': 42,\n",
       "  'I-AGE': 43,\n",
       "  'B-CITY': 44,\n",
       "  'I-CITY': 45,\n",
       "  'B-URL': 46,\n",
       "  'I-URL': 47,\n",
       "  'B-IPV4': 48,\n",
       "  'I-IPV4': 49,\n",
       "  'B-MIDDLENAME': 50,\n",
       "  'B-NEARBYGPSCOORDINATE': 51,\n",
       "  'I-NEARBYGPSCOORDINATE': 52,\n",
       "  'B-CURRENCYSYMBOL': 53,\n",
       "  'B-ACCOUNTNUMBER': 54,\n",
       "  'I-ACCOUNTNUMBER': 55,\n",
       "  'B-JOBAREA': 56,\n",
       "  'B-PHONENUMBER': 57,\n",
       "  'I-PHONENUMBER': 58,\n",
       "  'B-CREDITCARDISSUER': 59,\n",
       "  'I-CREDITCARDISSUER': 60,\n",
       "  'B-DATE': 61,\n",
       "  'I-DATE': 62,\n",
       "  'B-ACCOUNTNAME': 63,\n",
       "  'I-ACCOUNTNAME': 64,\n",
       "  'I-JOBAREA': 65,\n",
       "  'B-CURRENCY': 66,\n",
       "  'I-CURRENCY': 67,\n",
       "  'B-AMOUNT': 68,\n",
       "  'I-AMOUNT': 69,\n",
       "  'B-JOBTITLE': 70,\n",
       "  'I-JOBTITLE': 71,\n",
       "  'B-COMPANYNAME': 72,\n",
       "  'I-COMPANYNAME': 73,\n",
       "  'B-BUILDINGNUMBER': 74,\n",
       "  'I-BUILDINGNUMBER': 75,\n",
       "  'B-EMAIL': 76,\n",
       "  'I-EMAIL': 77,\n",
       "  'I-CURRENCYSYMBOL': 78,\n",
       "  'B-JOBTYPE': 79,\n",
       "  'I-JOBTYPE': 80,\n",
       "  'B-PHONEIMEI': 81,\n",
       "  'I-PHONEIMEI': 82,\n",
       "  'B-TIME': 83,\n",
       "  'I-TIME': 84,\n",
       "  'B-VEHICLEVIN': 85,\n",
       "  'I-VEHICLEVIN': 86,\n",
       "  'B-BIC': 87,\n",
       "  'I-BIC': 88,\n",
       "  'B-CURRENCYCODE': 89,\n",
       "  'I-CURRENCYCODE': 90,\n",
       "  'B-CREDITCARDNUMBER': 91,\n",
       "  'I-CREDITCARDNUMBER': 92,\n",
       "  'B-CREDITCARDCVV': 93,\n",
       "  'B-BITCOINADDRESS': 94,\n",
       "  'I-BITCOINADDRESS': 95,\n",
       "  'B-LITECOINADDRESS': 96,\n",
       "  'I-LITECOINADDRESS': 97,\n",
       "  'B-MAC': 98,\n",
       "  'I-MAC': 99,\n",
       "  'B-CURRENCYNAME': 100,\n",
       "  'I-CURRENCYNAME': 101,\n",
       "  'B-VEHICLEVRM': 102,\n",
       "  'I-VEHICLEVRM': 103,\n",
       "  'B-IPV6': 104,\n",
       "  'I-IPV6': 105,\n",
       "  'B-ETHEREUMADDRESS': 106,\n",
       "  'I-ETHEREUMADDRESS': 107,\n",
       "  'I-EYECOLOR': 108,\n",
       "  'I-MIDDLENAME': 109,\n",
       "  'I-CREDITCARDCVV': 110,\n",
       "  'I-SEX': 111},\n",
       " {0: 'O',\n",
       "  1: 'B-ORDINALDIRECTION',\n",
       "  2: 'B-IBAN',\n",
       "  3: 'I-IBAN',\n",
       "  4: 'B-IP',\n",
       "  5: 'I-IP',\n",
       "  6: 'B-MASKEDNUMBER',\n",
       "  7: 'I-MASKEDNUMBER',\n",
       "  8: 'B-USERAGENT',\n",
       "  9: 'I-USERAGENT',\n",
       "  10: 'B-PIN',\n",
       "  11: 'I-PIN',\n",
       "  12: 'B-AGE',\n",
       "  13: 'B-GENDER',\n",
       "  14: 'I-GENDER',\n",
       "  15: 'B-ZIPCODE',\n",
       "  16: 'I-ZIPCODE',\n",
       "  17: 'B-SEX',\n",
       "  18: 'B-EYECOLOR',\n",
       "  19: 'B-HEIGHT',\n",
       "  20: 'I-HEIGHT',\n",
       "  21: 'B-FIRSTNAME',\n",
       "  22: 'I-FIRSTNAME',\n",
       "  23: 'B-SSN',\n",
       "  24: 'I-SSN',\n",
       "  25: 'B-DOB',\n",
       "  26: 'I-DOB',\n",
       "  27: 'B-USERNAME',\n",
       "  28: 'I-USERNAME',\n",
       "  29: 'B-PASSWORD',\n",
       "  30: 'I-PASSWORD',\n",
       "  31: 'B-STREET',\n",
       "  32: 'I-STREET',\n",
       "  33: 'B-SECONDARYADDRESS',\n",
       "  34: 'I-SECONDARYADDRESS',\n",
       "  35: 'B-COUNTY',\n",
       "  36: 'I-COUNTY',\n",
       "  37: 'B-STATE',\n",
       "  38: 'I-STATE',\n",
       "  39: 'B-PREFIX',\n",
       "  40: 'I-PREFIX',\n",
       "  41: 'B-LASTNAME',\n",
       "  42: 'I-LASTNAME',\n",
       "  43: 'I-AGE',\n",
       "  44: 'B-CITY',\n",
       "  45: 'I-CITY',\n",
       "  46: 'B-URL',\n",
       "  47: 'I-URL',\n",
       "  48: 'B-IPV4',\n",
       "  49: 'I-IPV4',\n",
       "  50: 'B-MIDDLENAME',\n",
       "  51: 'B-NEARBYGPSCOORDINATE',\n",
       "  52: 'I-NEARBYGPSCOORDINATE',\n",
       "  53: 'B-CURRENCYSYMBOL',\n",
       "  54: 'B-ACCOUNTNUMBER',\n",
       "  55: 'I-ACCOUNTNUMBER',\n",
       "  56: 'B-JOBAREA',\n",
       "  57: 'B-PHONENUMBER',\n",
       "  58: 'I-PHONENUMBER',\n",
       "  59: 'B-CREDITCARDISSUER',\n",
       "  60: 'I-CREDITCARDISSUER',\n",
       "  61: 'B-DATE',\n",
       "  62: 'I-DATE',\n",
       "  63: 'B-ACCOUNTNAME',\n",
       "  64: 'I-ACCOUNTNAME',\n",
       "  65: 'I-JOBAREA',\n",
       "  66: 'B-CURRENCY',\n",
       "  67: 'I-CURRENCY',\n",
       "  68: 'B-AMOUNT',\n",
       "  69: 'I-AMOUNT',\n",
       "  70: 'B-JOBTITLE',\n",
       "  71: 'I-JOBTITLE',\n",
       "  72: 'B-COMPANYNAME',\n",
       "  73: 'I-COMPANYNAME',\n",
       "  74: 'B-BUILDINGNUMBER',\n",
       "  75: 'I-BUILDINGNUMBER',\n",
       "  76: 'B-EMAIL',\n",
       "  77: 'I-EMAIL',\n",
       "  78: 'I-CURRENCYSYMBOL',\n",
       "  79: 'B-JOBTYPE',\n",
       "  80: 'I-JOBTYPE',\n",
       "  81: 'B-PHONEIMEI',\n",
       "  82: 'I-PHONEIMEI',\n",
       "  83: 'B-TIME',\n",
       "  84: 'I-TIME',\n",
       "  85: 'B-VEHICLEVIN',\n",
       "  86: 'I-VEHICLEVIN',\n",
       "  87: 'B-BIC',\n",
       "  88: 'I-BIC',\n",
       "  89: 'B-CURRENCYCODE',\n",
       "  90: 'I-CURRENCYCODE',\n",
       "  91: 'B-CREDITCARDNUMBER',\n",
       "  92: 'I-CREDITCARDNUMBER',\n",
       "  93: 'B-CREDITCARDCVV',\n",
       "  94: 'B-BITCOINADDRESS',\n",
       "  95: 'I-BITCOINADDRESS',\n",
       "  96: 'B-LITECOINADDRESS',\n",
       "  97: 'I-LITECOINADDRESS',\n",
       "  98: 'B-MAC',\n",
       "  99: 'I-MAC',\n",
       "  100: 'B-CURRENCYNAME',\n",
       "  101: 'I-CURRENCYNAME',\n",
       "  102: 'B-VEHICLEVRM',\n",
       "  103: 'I-VEHICLEVRM',\n",
       "  104: 'B-IPV6',\n",
       "  105: 'I-IPV6',\n",
       "  106: 'B-ETHEREUMADDRESS',\n",
       "  107: 'I-ETHEREUMADDRESS',\n",
       "  108: 'I-EYECOLOR',\n",
       "  109: 'I-MIDDLENAME',\n",
       "  110: 'I-CREDITCARDCVV',\n",
       "  111: 'I-SEX'})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create label dict\n",
    "label2id = dict([(value,key) for key, value in enumerate(all_labels)])\n",
    "id2label = dict(map(reversed, label2id.items()))\n",
    "\n",
    "label2id, id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cc6bedb7-1960-49e5-b722-230a7746d1db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6496bede1c51450392a93882e44c0a53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/209229 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/7m8x2m5s2qv5xkd9zgpmblv00000gn/T/ipykernel_13443/1087438728.py:8: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  df.ner_tags = ner_tags\n"
     ]
    }
   ],
   "source": [
    "for j in tqdm(range(len(ner_tags))):\n",
    "    tags = ner_tags[j]\n",
    "    for i in range(len(tags)):\n",
    "        for k,v in label2id.items():\n",
    "            if tags[i] == k:\n",
    "                tags[i] = v\n",
    "    ner_tags[j] = tags\n",
    "df.ner_tags = ner_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "740458df-191c-4e02-8089-aa370b0e5fb3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_tags = [list(ner) for ner in ner_tags]\n",
    "ner_tags[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ff23a079-cdce-4818-a27f-b55f855f5f7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[['source_words']] = \"source_words\"\n",
    "source_words = [text.split(\" \") for text in source_texts]\n",
    "df.source_words = source_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dae8d23e-6507-4f44-929a-52d3bb70cbd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# removing rows where the len(tokenized_texts[i]) does not match len(ner_tags[i])\n",
    "idx = [i for i in range(len(ner_tags)) if len(tokenized_texts[i]) != len(ner_tags[i])]\n",
    "df = df.drop(index=idx).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c7cc0ae-0742-4a8d-91fe-61a35ec33603",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['masked_text', 'unmasked_text', 'privacy_mask', 'span_labels', 'bio_labels', 'tokenised_text', 'language', 'tt_lens', 'source_words'],\n",
       "    num_rows: 209261\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = datasets.Dataset.from_pandas(df)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "18bf5889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'masked_text': 'Our [ORDINALDIRECTION_1] campus is scheduled for a remodelling session. We aim to make the environment more conducive for learning. Donations can be made through [IBAN_1].',\n",
       " 'unmasked_text': 'Our Southwest campus is scheduled for a remodelling session. We aim to make the environment more conducive for learning. Donations can be made through PL06600900970901002009355772.',\n",
       " 'privacy_mask': \"{'[ORDINALDIRECTION_1]': 'Southwest', '[IBAN_1]': 'PL06600900970901002009355772'}\",\n",
       " 'span_labels': \"[[0, 4, 'O'], [4, 13, 'ORDINALDIRECTION_1'], [13, 151, 'O'], [151, 179, 'IBAN_1'], [179, 180, 'O']]\",\n",
       " 'bio_labels': [0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  0],\n",
       " 'tokenised_text': ['Our',\n",
       "  'Southwest',\n",
       "  'campus',\n",
       "  'is',\n",
       "  'scheduled',\n",
       "  'for',\n",
       "  'a',\n",
       "  're',\n",
       "  '##mo',\n",
       "  '##dell',\n",
       "  '##ing',\n",
       "  'session',\n",
       "  '.',\n",
       "  'We',\n",
       "  'aim',\n",
       "  'to',\n",
       "  'make',\n",
       "  'the',\n",
       "  'environment',\n",
       "  'more',\n",
       "  'con',\n",
       "  '##duc',\n",
       "  '##ive',\n",
       "  'for',\n",
       "  'learning',\n",
       "  '.',\n",
       "  'Dona',\n",
       "  '##tions',\n",
       "  'can',\n",
       "  'be',\n",
       "  'made',\n",
       "  'through',\n",
       "  'PL',\n",
       "  '##0',\n",
       "  '##66',\n",
       "  '##00',\n",
       "  '##900',\n",
       "  '##97',\n",
       "  '##0',\n",
       "  '##90',\n",
       "  '##100',\n",
       "  '##200',\n",
       "  '##9',\n",
       "  '##35',\n",
       "  '##57',\n",
       "  '##7',\n",
       "  '##2',\n",
       "  '.'],\n",
       " 'language': 'en',\n",
       " 'tt_lens': 2,\n",
       " 'source_words': ['Our',\n",
       "  'Southwest',\n",
       "  'campus',\n",
       "  'is',\n",
       "  'scheduled',\n",
       "  'for',\n",
       "  'a',\n",
       "  'remodelling',\n",
       "  'session.',\n",
       "  'We',\n",
       "  'aim',\n",
       "  'to',\n",
       "  'make',\n",
       "  'the',\n",
       "  'environment',\n",
       "  'more',\n",
       "  'conducive',\n",
       "  'for',\n",
       "  'learning.',\n",
       "  'Donations',\n",
       "  'can',\n",
       "  'be',\n",
       "  'made',\n",
       "  'through',\n",
       "  'PL06600900970901002009355772.']}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "951e9dd6-5e09-48d7-9d09-529bc33af07b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def align_labels(example):\n",
    "    tokenized_input = tokenizer(example[\"tokenised_text\"], is_split_into_words=True)\n",
    "    tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "    word_ids = tokenized_input.word_ids()\n",
    "    aligned_labels = [-100 if i is None else example[\"bio_labels\"][i] for i in word_ids]\n",
    "    tokenized_input['labels'] = aligned_labels\n",
    "    return tokenized_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8db8f2d7-4180-4aee-ad80-badf03240963",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92 92 92\n"
     ]
    }
   ],
   "source": [
    "al = align_labels(dataset[0])\n",
    "print(len(al['input_ids']), len(al['attention_mask']), len(al['labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "39baa3f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 61694, 10133, 102], 'attention_mask': [1, 1, 1, 1]}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4d4d678b-c154-4f41-8f0b-83f0a0b08fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_all_tokens = True\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer.encode_plus(examples[\"tokenised_text\"], is_split_into_words=True, truncation=True, max_length=512)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"bio_labels\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
    "            # ignored in the loss function.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            # We set the label for the first token of each word.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
    "            # the label_all_tokens flag.\n",
    "            else:\n",
    "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8ae6e964-d915-488b-b03a-cf262096cb6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6222e103fcbd4e6f93e659e2c7a794fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/209261 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1415 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (885 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (607 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1167 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1077 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "ename": "TimeoutError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/py10/lib/python3.10/site-packages/datasets/utils/py_utils.py:1380\u001b[0m, in \u001b[0;36miflatmap_unordered\u001b[0;34m(pool, func, kwargs_iterable)\u001b[0m\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1380\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[43mqueue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1381\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Empty:\n",
      "File \u001b[0;32m<string>:2\u001b[0m, in \u001b[0;36mget\u001b[0;34m(self, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/py10/lib/python3.10/site-packages/multiprocess/managers.py:818\u001b[0m, in \u001b[0;36mBaseProxy._callmethod\u001b[0;34m(self, methodname, args, kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m conn\u001b[38;5;241m.\u001b[39msend((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id, methodname, args, kwds))\n\u001b[0;32m--> 818\u001b[0m kind, result \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    820\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#RETURN\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/py10/lib/python3.10/site-packages/multiprocess/connection.py:253\u001b[0m, in \u001b[0;36m_ConnectionBase.recv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 253\u001b[0m buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _ForkingPickler\u001b[38;5;241m.\u001b[39mloads(buf\u001b[38;5;241m.\u001b[39mgetbuffer())\n",
      "File \u001b[0;32m~/miniconda3/envs/py10/lib/python3.10/site-packages/multiprocess/connection.py:417\u001b[0m, in \u001b[0;36mConnection._recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_recv_bytes\u001b[39m(\u001b[38;5;28mself\u001b[39m, maxsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 417\u001b[0m     buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    418\u001b[0m     size, \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!i\u001b[39m\u001b[38;5;124m\"\u001b[39m, buf\u001b[38;5;241m.\u001b[39mgetvalue())\n",
      "File \u001b[0;32m~/miniconda3/envs/py10/lib/python3.10/site-packages/multiprocess/connection.py:382\u001b[0m, in \u001b[0;36mConnection._recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m remaining \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 382\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43malign_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumn_names\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py10/lib/python3.10/site-packages/datasets/arrow_dataset.py:592\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    591\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 592\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    593\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py10/lib/python3.10/site-packages/datasets/arrow_dataset.py:557\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    550\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[1;32m    555\u001b[0m }\n\u001b[1;32m    556\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 557\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    558\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    559\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py10/lib/python3.10/site-packages/datasets/arrow_dataset.py:3189\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3182\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpawning \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_proc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m processes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3183\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mtqdm(\n\u001b[1;32m   3184\u001b[0m     disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mis_progress_bar_enabled(),\n\u001b[1;32m   3185\u001b[0m     unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3186\u001b[0m     total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[1;32m   3187\u001b[0m     desc\u001b[38;5;241m=\u001b[39m(desc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (num_proc=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_proc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3188\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m-> 3189\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m rank, done, content \u001b[38;5;129;01min\u001b[39;00m iflatmap_unordered(\n\u001b[1;32m   3190\u001b[0m         pool, Dataset\u001b[38;5;241m.\u001b[39m_map_single, kwargs_iterable\u001b[38;5;241m=\u001b[39mkwargs_per_job\n\u001b[1;32m   3191\u001b[0m     ):\n\u001b[1;32m   3192\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[1;32m   3193\u001b[0m             shards_done \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/py10/lib/python3.10/site-packages/datasets/utils/py_utils.py:1394\u001b[0m, in \u001b[0;36miflatmap_unordered\u001b[0;34m(pool, func, kwargs_iterable)\u001b[0m\n\u001b[1;32m   1391\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1392\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pool_changed:\n\u001b[1;32m   1393\u001b[0m         \u001b[38;5;66;03m# we get the result in case there's an error to raise\u001b[39;00m\n\u001b[0;32m-> 1394\u001b[0m         [async_result\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m async_result \u001b[38;5;129;01min\u001b[39;00m async_results]\n",
      "File \u001b[0;32m~/miniconda3/envs/py10/lib/python3.10/site-packages/datasets/utils/py_utils.py:1394\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1391\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1392\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pool_changed:\n\u001b[1;32m   1393\u001b[0m         \u001b[38;5;66;03m# we get the result in case there's an error to raise\u001b[39;00m\n\u001b[0;32m-> 1394\u001b[0m         [\u001b[43masync_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m async_result \u001b[38;5;129;01min\u001b[39;00m async_results]\n",
      "File \u001b[0;32m~/miniconda3/envs/py10/lib/python3.10/site-packages/multiprocess/pool.py:770\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    769\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[0;32m--> 770\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_success:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "\u001b[0;31mTimeoutError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x = dataset.map(align_labels, num_proc=8, remove_columns=dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e2d5d4c6-5d52-4612-bce9-0c65a98181b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenized_dataset = x.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b8732f21-bcd6-47bb-839a-13e66b84c6cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 167408\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 41853\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e03ae609-8ce5-4521-b8e5-f707267e7b08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "07f3f6fa-b381-4719-bbc5-556edf2731a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/7m8x2m5s2qv5xkd9zgpmblv00000gn/T/ipykernel_11327/1110732161.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = datasets.load_metric(\"seqeval\")\n"
     ]
    }
   ],
   "source": [
    "metric = datasets.load_metric(\"seqeval\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [all_labels[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [all_labels[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    flattened_results = {\n",
    "        \"overall_precision\": results[\"overall_precision\"],\n",
    "        \"overall_recall\": results[\"overall_recall\"],\n",
    "        \"overall_f1\": results[\"overall_f1\"],\n",
    "        \"overall_accuracy\": results[\"overall_accuracy\"],\n",
    "    }\n",
    "\n",
    "    for k in results.keys():\n",
    "        if (k not in flattened_results.keys()):\n",
    "            flattened_results[f\"{k}_f1\"] = results[k][\"f1\"]\n",
    "\n",
    "    return flattened_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9027a465-848e-4be9-aa5d-1efd90aad2c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57850fe1d62d40369ea66cab83141662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/542M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-multilingual-cased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"B-ORDINALDIRECTION\",\n",
      "    \"2\": \"B-IBAN\",\n",
      "    \"3\": \"I-IBAN\",\n",
      "    \"4\": \"B-IP\",\n",
      "    \"5\": \"I-IP\",\n",
      "    \"6\": \"B-MASKEDNUMBER\",\n",
      "    \"7\": \"I-MASKEDNUMBER\",\n",
      "    \"8\": \"B-USERAGENT\",\n",
      "    \"9\": \"I-USERAGENT\",\n",
      "    \"10\": \"B-PIN\",\n",
      "    \"11\": \"I-PIN\",\n",
      "    \"12\": \"B-AGE\",\n",
      "    \"13\": \"B-GENDER\",\n",
      "    \"14\": \"I-GENDER\",\n",
      "    \"15\": \"B-ZIPCODE\",\n",
      "    \"16\": \"I-ZIPCODE\",\n",
      "    \"17\": \"B-SEX\",\n",
      "    \"18\": \"B-EYECOLOR\",\n",
      "    \"19\": \"B-HEIGHT\",\n",
      "    \"20\": \"I-HEIGHT\",\n",
      "    \"21\": \"B-FIRSTNAME\",\n",
      "    \"22\": \"I-FIRSTNAME\",\n",
      "    \"23\": \"B-SSN\",\n",
      "    \"24\": \"I-SSN\",\n",
      "    \"25\": \"B-DOB\",\n",
      "    \"26\": \"I-DOB\",\n",
      "    \"27\": \"B-USERNAME\",\n",
      "    \"28\": \"I-USERNAME\",\n",
      "    \"29\": \"B-PASSWORD\",\n",
      "    \"30\": \"I-PASSWORD\",\n",
      "    \"31\": \"B-STREET\",\n",
      "    \"32\": \"I-STREET\",\n",
      "    \"33\": \"B-SECONDARYADDRESS\",\n",
      "    \"34\": \"I-SECONDARYADDRESS\",\n",
      "    \"35\": \"B-COUNTY\",\n",
      "    \"36\": \"I-COUNTY\",\n",
      "    \"37\": \"B-STATE\",\n",
      "    \"38\": \"I-STATE\",\n",
      "    \"39\": \"B-PREFIX\",\n",
      "    \"40\": \"I-PREFIX\",\n",
      "    \"41\": \"B-LASTNAME\",\n",
      "    \"42\": \"I-LASTNAME\",\n",
      "    \"43\": \"I-AGE\",\n",
      "    \"44\": \"B-CITY\",\n",
      "    \"45\": \"I-CITY\",\n",
      "    \"46\": \"B-URL\",\n",
      "    \"47\": \"I-URL\",\n",
      "    \"48\": \"B-IPV4\",\n",
      "    \"49\": \"I-IPV4\",\n",
      "    \"50\": \"B-MIDDLENAME\",\n",
      "    \"51\": \"B-NEARBYGPSCOORDINATE\",\n",
      "    \"52\": \"I-NEARBYGPSCOORDINATE\",\n",
      "    \"53\": \"B-CURRENCYSYMBOL\",\n",
      "    \"54\": \"B-ACCOUNTNUMBER\",\n",
      "    \"55\": \"I-ACCOUNTNUMBER\",\n",
      "    \"56\": \"B-JOBAREA\",\n",
      "    \"57\": \"B-PHONENUMBER\",\n",
      "    \"58\": \"I-PHONENUMBER\",\n",
      "    \"59\": \"B-CREDITCARDISSUER\",\n",
      "    \"60\": \"I-CREDITCARDISSUER\",\n",
      "    \"61\": \"B-DATE\",\n",
      "    \"62\": \"I-DATE\",\n",
      "    \"63\": \"B-ACCOUNTNAME\",\n",
      "    \"64\": \"I-ACCOUNTNAME\",\n",
      "    \"65\": \"I-JOBAREA\",\n",
      "    \"66\": \"B-CURRENCY\",\n",
      "    \"67\": \"I-CURRENCY\",\n",
      "    \"68\": \"B-AMOUNT\",\n",
      "    \"69\": \"I-AMOUNT\",\n",
      "    \"70\": \"B-JOBTITLE\",\n",
      "    \"71\": \"I-JOBTITLE\",\n",
      "    \"72\": \"B-COMPANYNAME\",\n",
      "    \"73\": \"I-COMPANYNAME\",\n",
      "    \"74\": \"B-BUILDINGNUMBER\",\n",
      "    \"75\": \"I-BUILDINGNUMBER\",\n",
      "    \"76\": \"B-EMAIL\",\n",
      "    \"77\": \"I-EMAIL\",\n",
      "    \"78\": \"I-CURRENCYSYMBOL\",\n",
      "    \"79\": \"B-JOBTYPE\",\n",
      "    \"80\": \"I-JOBTYPE\",\n",
      "    \"81\": \"B-PHONEIMEI\",\n",
      "    \"82\": \"I-PHONEIMEI\",\n",
      "    \"83\": \"B-TIME\",\n",
      "    \"84\": \"I-TIME\",\n",
      "    \"85\": \"B-VEHICLEVIN\",\n",
      "    \"86\": \"I-VEHICLEVIN\",\n",
      "    \"87\": \"B-BIC\",\n",
      "    \"88\": \"I-BIC\",\n",
      "    \"89\": \"B-CURRENCYCODE\",\n",
      "    \"90\": \"I-CURRENCYCODE\",\n",
      "    \"91\": \"B-CREDITCARDNUMBER\",\n",
      "    \"92\": \"I-CREDITCARDNUMBER\",\n",
      "    \"93\": \"B-CREDITCARDCVV\",\n",
      "    \"94\": \"B-BITCOINADDRESS\",\n",
      "    \"95\": \"I-BITCOINADDRESS\",\n",
      "    \"96\": \"B-LITECOINADDRESS\",\n",
      "    \"97\": \"I-LITECOINADDRESS\",\n",
      "    \"98\": \"B-MAC\",\n",
      "    \"99\": \"I-MAC\",\n",
      "    \"100\": \"B-CURRENCYNAME\",\n",
      "    \"101\": \"I-CURRENCYNAME\",\n",
      "    \"102\": \"B-VEHICLEVRM\",\n",
      "    \"103\": \"I-VEHICLEVRM\",\n",
      "    \"104\": \"B-IPV6\",\n",
      "    \"105\": \"I-IPV6\",\n",
      "    \"106\": \"B-ETHEREUMADDRESS\",\n",
      "    \"107\": \"I-ETHEREUMADDRESS\",\n",
      "    \"108\": \"I-EYECOLOR\",\n",
      "    \"109\": \"I-MIDDLENAME\",\n",
      "    \"110\": \"I-CREDITCARDCVV\",\n",
      "    \"111\": \"I-SEX\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"B-ACCOUNTNAME\": 63,\n",
      "    \"B-ACCOUNTNUMBER\": 54,\n",
      "    \"B-AGE\": 12,\n",
      "    \"B-AMOUNT\": 68,\n",
      "    \"B-BIC\": 87,\n",
      "    \"B-BITCOINADDRESS\": 94,\n",
      "    \"B-BUILDINGNUMBER\": 74,\n",
      "    \"B-CITY\": 44,\n",
      "    \"B-COMPANYNAME\": 72,\n",
      "    \"B-COUNTY\": 35,\n",
      "    \"B-CREDITCARDCVV\": 93,\n",
      "    \"B-CREDITCARDISSUER\": 59,\n",
      "    \"B-CREDITCARDNUMBER\": 91,\n",
      "    \"B-CURRENCY\": 66,\n",
      "    \"B-CURRENCYCODE\": 89,\n",
      "    \"B-CURRENCYNAME\": 100,\n",
      "    \"B-CURRENCYSYMBOL\": 53,\n",
      "    \"B-DATE\": 61,\n",
      "    \"B-DOB\": 25,\n",
      "    \"B-EMAIL\": 76,\n",
      "    \"B-ETHEREUMADDRESS\": 106,\n",
      "    \"B-EYECOLOR\": 18,\n",
      "    \"B-FIRSTNAME\": 21,\n",
      "    \"B-GENDER\": 13,\n",
      "    \"B-HEIGHT\": 19,\n",
      "    \"B-IBAN\": 2,\n",
      "    \"B-IP\": 4,\n",
      "    \"B-IPV4\": 48,\n",
      "    \"B-IPV6\": 104,\n",
      "    \"B-JOBAREA\": 56,\n",
      "    \"B-JOBTITLE\": 70,\n",
      "    \"B-JOBTYPE\": 79,\n",
      "    \"B-LASTNAME\": 41,\n",
      "    \"B-LITECOINADDRESS\": 96,\n",
      "    \"B-MAC\": 98,\n",
      "    \"B-MASKEDNUMBER\": 6,\n",
      "    \"B-MIDDLENAME\": 50,\n",
      "    \"B-NEARBYGPSCOORDINATE\": 51,\n",
      "    \"B-ORDINALDIRECTION\": 1,\n",
      "    \"B-PASSWORD\": 29,\n",
      "    \"B-PHONEIMEI\": 81,\n",
      "    \"B-PHONENUMBER\": 57,\n",
      "    \"B-PIN\": 10,\n",
      "    \"B-PREFIX\": 39,\n",
      "    \"B-SECONDARYADDRESS\": 33,\n",
      "    \"B-SEX\": 17,\n",
      "    \"B-SSN\": 23,\n",
      "    \"B-STATE\": 37,\n",
      "    \"B-STREET\": 31,\n",
      "    \"B-TIME\": 83,\n",
      "    \"B-URL\": 46,\n",
      "    \"B-USERAGENT\": 8,\n",
      "    \"B-USERNAME\": 27,\n",
      "    \"B-VEHICLEVIN\": 85,\n",
      "    \"B-VEHICLEVRM\": 102,\n",
      "    \"B-ZIPCODE\": 15,\n",
      "    \"I-ACCOUNTNAME\": 64,\n",
      "    \"I-ACCOUNTNUMBER\": 55,\n",
      "    \"I-AGE\": 43,\n",
      "    \"I-AMOUNT\": 69,\n",
      "    \"I-BIC\": 88,\n",
      "    \"I-BITCOINADDRESS\": 95,\n",
      "    \"I-BUILDINGNUMBER\": 75,\n",
      "    \"I-CITY\": 45,\n",
      "    \"I-COMPANYNAME\": 73,\n",
      "    \"I-COUNTY\": 36,\n",
      "    \"I-CREDITCARDCVV\": 110,\n",
      "    \"I-CREDITCARDISSUER\": 60,\n",
      "    \"I-CREDITCARDNUMBER\": 92,\n",
      "    \"I-CURRENCY\": 67,\n",
      "    \"I-CURRENCYCODE\": 90,\n",
      "    \"I-CURRENCYNAME\": 101,\n",
      "    \"I-CURRENCYSYMBOL\": 78,\n",
      "    \"I-DATE\": 62,\n",
      "    \"I-DOB\": 26,\n",
      "    \"I-EMAIL\": 77,\n",
      "    \"I-ETHEREUMADDRESS\": 107,\n",
      "    \"I-EYECOLOR\": 108,\n",
      "    \"I-FIRSTNAME\": 22,\n",
      "    \"I-GENDER\": 14,\n",
      "    \"I-HEIGHT\": 20,\n",
      "    \"I-IBAN\": 3,\n",
      "    \"I-IP\": 5,\n",
      "    \"I-IPV4\": 49,\n",
      "    \"I-IPV6\": 105,\n",
      "    \"I-JOBAREA\": 65,\n",
      "    \"I-JOBTITLE\": 71,\n",
      "    \"I-JOBTYPE\": 80,\n",
      "    \"I-LASTNAME\": 42,\n",
      "    \"I-LITECOINADDRESS\": 97,\n",
      "    \"I-MAC\": 99,\n",
      "    \"I-MASKEDNUMBER\": 7,\n",
      "    \"I-MIDDLENAME\": 109,\n",
      "    \"I-NEARBYGPSCOORDINATE\": 52,\n",
      "    \"I-PASSWORD\": 30,\n",
      "    \"I-PHONEIMEI\": 82,\n",
      "    \"I-PHONENUMBER\": 58,\n",
      "    \"I-PIN\": 11,\n",
      "    \"I-PREFIX\": 40,\n",
      "    \"I-SECONDARYADDRESS\": 34,\n",
      "    \"I-SEX\": 111,\n",
      "    \"I-SSN\": 24,\n",
      "    \"I-STATE\": 38,\n",
      "    \"I-STREET\": 32,\n",
      "    \"I-TIME\": 84,\n",
      "    \"I-URL\": 47,\n",
      "    \"I-USERAGENT\": 9,\n",
      "    \"I-USERNAME\": 28,\n",
      "    \"I-VEHICLEVIN\": 86,\n",
      "    \"I-VEHICLEVRM\": 103,\n",
      "    \"I-ZIPCODE\": 16,\n",
      "    \"O\": 0\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.34.0\",\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(model_name, num_labels=len(all_labels), label2id=label2id, id2label=id2label)\n",
    "print(model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "36bb2c00-a05e-41ca-b60c-e71bc6cdb6c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=f\"{model_name}_finetuned_ai4privacy\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    overwrite_output_dir=True,\n",
    "    warmup_ratio=0.2,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy='epoch',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=1,\n",
    "    lr_scheduler_type='cosine_with_restarts',\n",
    "    report_to='wandb',\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_dataset[\"test\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b47741cd-e504-4c48-b1c8-b466f2d8c064",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msripaadsrinivasan\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sripaadsrinivasan/Projects/ai4privacy/notebooks/wandb/run-20231020_160741-rte30ow0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sripaadsrinivasan/huggingface/runs/rte30ow0' target=\"_blank\">golden-cosmos-1041</a></strong> to <a href='https://wandb.ai/sripaadsrinivasan/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sripaadsrinivasan/huggingface' target=\"_blank\">https://wandb.ai/sripaadsrinivasan/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sripaadsrinivasan/huggingface/runs/rte30ow0' target=\"_blank\">https://wandb.ai/sripaadsrinivasan/huggingface/runs/rte30ow0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a ElectraTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='5089' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  29/5089 02:55 < 9:08:36, 0.15 it/s, Epoch 0.04/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 5.52 GB, other allocations: 3.45 GB, max allowed: 9.07 GB). Tried to allocate 119.23 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_result \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m test_result \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate(tokenized_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      4\u001b[0m train_metrics \u001b[38;5;241m=\u001b[39m train_result\u001b[38;5;241m.\u001b[39mmetrics\n",
      "File \u001b[0;32m~/miniconda3/envs/py10/lib/python3.10/site-packages/transformers/trainer.py:1591\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1589\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1590\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1591\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1592\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1596\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py10/lib/python3.10/site-packages/transformers/trainer.py:1971\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1969\u001b[0m     optimizer_was_run \u001b[38;5;241m=\u001b[39m scale_before \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m scale_after\n\u001b[1;32m   1970\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1971\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1972\u001b[0m     optimizer_was_run \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39moptimizer_step_was_skipped\n\u001b[1;32m   1974\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optimizer_was_run:\n\u001b[1;32m   1975\u001b[0m     \u001b[38;5;66;03m# Delay optimizer scheduling until metrics are generated\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py10/lib/python3.10/site-packages/accelerate/optimizer.py:145\u001b[0m, in \u001b[0;36mAcceleratedOptimizer.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accelerate_step_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:68\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     67\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m---> 68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py10/lib/python3.10/site-packages/torch/optim/optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    370\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m             )\n\u001b[0;32m--> 373\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py10/lib/python3.10/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/miniconda3/envs/py10/lib/python3.10/site-packages/torch/optim/adamw.py:184\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    171\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    174\u001b[0m         group,\n\u001b[1;32m    175\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    181\u001b[0m         state_steps,\n\u001b[1;32m    182\u001b[0m     )\n\u001b[0;32m--> 184\u001b[0m     \u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/miniconda3/envs/py10/lib/python3.10/site-packages/torch/optim/adamw.py:335\u001b[0m, in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    333\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adamw\n\u001b[0;32m--> 335\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py10/lib/python3.10/site-packages/torch/optim/adamw.py:464\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    462\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 464\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    466\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n\u001b[1;32m    468\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 5.52 GB, other allocations: 3.45 GB, max allowed: 9.07 GB). Tried to allocate 119.23 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "train_result = trainer.train()\n",
    "test_result = trainer.evaluate(tokenized_dataset['test'])\n",
    "\n",
    "train_metrics = train_result.metrics\n",
    "test_metrics = test_result.metrics\n",
    "\n",
    "max_train_samples = len(tokenized_dataset['train'])\n",
    "max_eval_samples = len(tokenized_dataset['test'])\n",
    "\n",
    "train_metrics[\"train_samples\"] = min(max_train_samples, len(tokenized_dataset['train']))\n",
    "trainer.log_metrics(\"train\", train_metrics)\n",
    "\n",
    "test_metrics[\"eval_samples\"] = min(max_eval_samples, len(tokenized_dataset['test']))\n",
    "trainer.log_metrics(\"eval\", test_metrics)\n",
    "\n",
    "trainer.save_metrics(\"train\", train_metrics)\n",
    "trainer.save_metrics(\"eval\", test_metrics)\n",
    "\n",
    "trainer.save_state()\n",
    "trainer.save_model(args.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b7d6ef-2cfc-4d3a-89a2-13d962203194",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
