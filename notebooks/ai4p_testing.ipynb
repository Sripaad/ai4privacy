{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing ai4p model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = pipeline(\"token-classification\", \"Isotonic/distilbert_finetuned_ai4privacy\", device=-1, torch_dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"My name is Claraly and I live in Berkeley, California.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = gen(text, aggregation_strategy=\"simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_entities(output, text):\n",
    "    word_to_entity_group = dict(\n",
    "    (text[token[\"start\"] : token[\"end\"]], token[\"entity_group\"]) for token in output\n",
    ")\n",
    "    for i, token in enumerate(output):\n",
    "        word = list(word_to_entity_group.keys())[i]\n",
    "        text = text.replace(word, f\"[{word_to_entity_group[word]}]\")\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"These instructions apply to section-based themes (Responsive 6.0+, Retina 4.0+, Parallax 3.0+ Turbo 2.0+, Mobilia 5.0+). What theme version am I using? On your Collections pages & Featured Collections sections, you can easily show the secondary image of a product on hover by enabling one of the theme's built-in settings! Your Collection pages & Featured Collections sections will now display the secondary product image just by hovering over that product image thumbnail. Does this feature apply to all sections of the theme or just specific ones as listed in the text material?\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_entities(output, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adapters Testrun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from adapters import AutoAdapterModel\n",
    "import adapters.composition as ac\n",
    "\n",
    "\n",
    "model = AutoAdapterModel.from_pretrained(\"roberta-base\")\n",
    "wnut_17 = model.load_adapter(\"AdapterHub/roberta-base-pf-wnut_17\", source=\"hf\")\n",
    "conll2003 = model.load_adapter(\"AdapterHub/roberta-base-pf-conll2003\", source=\"hf\")\n",
    "\n",
    "model.active_adapters = ac.Parallel(wnut_17, conll2003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"My name is Sarah and I live in Berkeley, California.\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(text, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output1, output2  = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_labels_dict('wnut_17'), model.get_labels_dict('conll2003')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def analyze_sentence(sentence):\n",
    "  tokens = tokenizer.tokenize(sentence)\n",
    "  input_ids = torch.tensor(tokenizer.convert_tokens_to_ids(tokens))\n",
    "  outputs = model(input_ids)\n",
    "\n",
    "  # Post-process NER output wnut_17\n",
    "  ner_labels_map = model.get_labels_dict(\"wnut_17\")\n",
    "  ner_label_ids = torch.argmax(outputs[0].logits, dim=2).numpy().squeeze().tolist()\n",
    "  ner_labels = [ner_labels_map[id_] for id_ in ner_label_ids]\n",
    "  annotated = []\n",
    "  for token, label_id in zip(tokens, ner_label_ids):\n",
    "    token = token.replace('\\u0120', '')\n",
    "    label = ner_labels_map[label_id]\n",
    "    annotated.append(f\"{token}<{label}>\" if label != \"O\" else token)\n",
    "  print(\"NER Wnut_17: \" + \" \".join(annotated))\n",
    "\n",
    "  # Post-process NER output conll2003\n",
    "  ner_labels_map = model.get_labels_dict(\"conll2003\")\n",
    "  ner_label_ids = torch.argmax(outputs[1].logits, dim=2).numpy().squeeze().tolist()\n",
    "  ner_labels = [ner_labels_map[id_] for id_ in ner_label_ids]\n",
    "  annotated = []\n",
    "  for token, label_id in zip(tokens, ner_label_ids):\n",
    "    token = token.replace('\\u0120', '')\n",
    "    label = ner_labels_map[label_id]\n",
    "    annotated.append(f\"{token}<{label}>\" if label != \"O\" else token)\n",
    "  print(\"NER conll2003: \" + \" \".join(annotated))\n",
    "\n",
    "  # # Post-process classifier output\n",
    "  # classifier_labels = model.get_labels_dict(classifier_adapter)\n",
    "  # label_id = torch.argmax(outputs[1].logits).item()\n",
    "  # print(\"Classifier: \" + classifier_labels[label_id])\n",
    "  # print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_sentence(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "  \"A man in central Germany tried to leave his house by the front door only to find a brick wall there.\",\n",
    "  \"The Met Office has issued a yellow weather warning for ice across most of Wales.\",\n",
    "  \"A vibrant animation telling stories of indigenous Australia will be projected on to the Sydney Opera House every night at sunset.\"\n",
    "]\n",
    "\n",
    "for sentence in sentences:\n",
    "  analyze_sentence(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lora parallel inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from adapters import AutoAdapterModel\n",
    "import adapters.composition as ac\n",
    "\n",
    "\n",
    "model = AutoAdapterModel.from_pretrained(\"roberta-base\")\n",
    "wnut_17 = model.load_adapter(\"AdapterHub/roberta-base-pf-wnut_17\", source=\"hf\")\n",
    "conll2003 = model.load_adapter(\"AdapterHub/roberta-base-pf-conll2003\", source=\"hf\")\n",
    "\n",
    "model.active_adapters = ac.Parallel(wnut_17, conll2003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {\n",
    "    \"0\": \"O\",\n",
    "    \"1\": \"B-PHONEIMEI\",\n",
    "    \"2\": \"I-PHONEIMEI\",\n",
    "    \"3\": \"B-JOBAREA\",\n",
    "    \"4\": \"B-FIRSTNAME\",\n",
    "    \"5\": \"I-FIRSTNAME\",\n",
    "    \"6\": \"B-VEHICLEVIN\",\n",
    "    \"7\": \"I-VEHICLEVIN\",\n",
    "    \"8\": \"B-AGE\",\n",
    "    \"9\": \"B-GENDER\",\n",
    "    \"10\": \"I-GENDER\",\n",
    "    \"11\": \"B-HEIGHT\",\n",
    "    \"12\": \"I-HEIGHT\",\n",
    "    \"13\": \"B-BUILDINGNUMBER\",\n",
    "    \"14\": \"I-BUILDINGNUMBER\",\n",
    "    \"15\": \"B-MASKEDNUMBER\",\n",
    "    \"16\": \"I-MASKEDNUMBER\",\n",
    "    \"17\": \"B-PASSWORD\",\n",
    "    \"18\": \"I-PASSWORD\",\n",
    "    \"19\": \"B-DOB\",\n",
    "    \"20\": \"I-DOB\",\n",
    "    \"21\": \"B-IPV6\",\n",
    "    \"22\": \"I-IPV6\",\n",
    "    \"23\": \"B-NEARBYGPSCOORDINATE\",\n",
    "    \"24\": \"I-NEARBYGPSCOORDINATE\",\n",
    "    \"25\": \"B-USERAGENT\",\n",
    "    \"26\": \"I-USERAGENT\",\n",
    "    \"27\": \"B-TIME\",\n",
    "    \"28\": \"I-TIME\",\n",
    "    \"29\": \"B-JOBTITLE\",\n",
    "    \"30\": \"I-JOBTITLE\",\n",
    "    \"31\": \"B-COUNTY\",\n",
    "    \"32\": \"B-EMAIL\",\n",
    "    \"33\": \"I-EMAIL\",\n",
    "    \"34\": \"B-ACCOUNTNUMBER\",\n",
    "    \"35\": \"I-ACCOUNTNUMBER\",\n",
    "    \"36\": \"B-PIN\",\n",
    "    \"37\": \"I-PIN\",\n",
    "    \"38\": \"B-EYECOLOR\",\n",
    "    \"39\": \"I-EYECOLOR\",\n",
    "    \"40\": \"B-LASTNAME\",\n",
    "    \"41\": \"I-LASTNAME\",\n",
    "    \"42\": \"I-JOBAREA\",\n",
    "    \"43\": \"B-IPV4\",\n",
    "    \"44\": \"I-IPV4\",\n",
    "    \"45\": \"B-DATE\",\n",
    "    \"46\": \"I-DATE\",\n",
    "    \"47\": \"B-STREET\",\n",
    "    \"48\": \"I-STREET\",\n",
    "    \"49\": \"B-CITY\",\n",
    "    \"50\": \"I-CITY\",\n",
    "    \"51\": \"B-PREFIX\",\n",
    "    \"52\": \"I-PREFIX\",\n",
    "    \"53\": \"B-CREDITCARDISSUER\",\n",
    "    \"54\": \"B-CREDITCARDNUMBER\",\n",
    "    \"55\": \"I-CREDITCARDNUMBER\",\n",
    "    \"56\": \"I-CREDITCARDISSUER\",\n",
    "    \"57\": \"B-MIDDLENAME\",\n",
    "    \"58\": \"B-STATE\",\n",
    "    \"59\": \"I-STATE\",\n",
    "    \"60\": \"B-VEHICLEVRM\",\n",
    "    \"61\": \"I-VEHICLEVRM\",\n",
    "    \"62\": \"B-ORDINALDIRECTION\",\n",
    "    \"63\": \"B-SEX\",\n",
    "    \"64\": \"B-JOBTYPE\",\n",
    "    \"65\": \"I-JOBTYPE\",\n",
    "    \"66\": \"B-CURRENCYCODE\",\n",
    "    \"67\": \"I-CURRENCYCODE\",\n",
    "    \"68\": \"B-CURRENCYSYMBOL\",\n",
    "    \"69\": \"I-AMOUNT\",\n",
    "    \"70\": \"B-ACCOUNTNAME\",\n",
    "    \"71\": \"I-ACCOUNTNAME\",\n",
    "    \"72\": \"B-BITCOINADDRESS\",\n",
    "    \"73\": \"I-BITCOINADDRESS\",\n",
    "    \"74\": \"B-LITECOINADDRESS\",\n",
    "    \"75\": \"I-LITECOINADDRESS\",\n",
    "    \"76\": \"B-PHONENUMBER\",\n",
    "    \"77\": \"I-PHONENUMBER\",\n",
    "    \"78\": \"B-MAC\",\n",
    "    \"79\": \"I-MAC\",\n",
    "    \"80\": \"B-CURRENCY\",\n",
    "    \"81\": \"B-IBAN\",\n",
    "    \"82\": \"I-IBAN\",\n",
    "    \"83\": \"B-COMPANYNAME\",\n",
    "    \"84\": \"I-COMPANYNAME\",\n",
    "    \"85\": \"B-CURRENCYNAME\",\n",
    "    \"86\": \"I-CURRENCYNAME\",\n",
    "    \"87\": \"I-CURRENCYSYMBOL\",\n",
    "    \"88\": \"B-ZIPCODE\",\n",
    "    \"89\": \"I-ZIPCODE\",\n",
    "    \"90\": \"B-SSN\",\n",
    "    \"91\": \"I-SSN\",\n",
    "    \"92\": \"B-AMOUNT\",\n",
    "    \"93\": \"I-CURRENCY\",\n",
    "    \"94\": \"B-URL\",\n",
    "    \"95\": \"I-URL\",\n",
    "    \"96\": \"B-IP\",\n",
    "    \"97\": \"I-IP\",\n",
    "    \"98\": \"B-SECONDARYADDRESS\",\n",
    "    \"99\": \"I-SECONDARYADDRESS\",\n",
    "    \"100\": \"B-USERNAME\",\n",
    "    \"101\": \"I-USERNAME\",\n",
    "    \"102\": \"B-ETHEREUMADDRESS\",\n",
    "    \"103\": \"I-ETHEREUMADDRESS\",\n",
    "    \"104\": \"B-CREDITCARDCVV\",\n",
    "    \"105\": \"I-CREDITCARDCVV\",\n",
    "    \"106\": \"I-COUNTY\",\n",
    "    \"107\": \"I-AGE\",\n",
    "    \"108\": \"I-MIDDLENAME\",\n",
    "    \"109\": \"B-BIC\",\n",
    "    \"110\": \"I-BIC\"\n",
    "  },\n",
    "\n",
    "label2id = {\n",
    "    \"B-ACCOUNTNAME\": 70,\n",
    "    \"B-ACCOUNTNUMBER\": 34,\n",
    "    \"B-AGE\": 8,\n",
    "    \"B-AMOUNT\": 92,\n",
    "    \"B-BIC\": 109,\n",
    "    \"B-BITCOINADDRESS\": 72,\n",
    "    \"B-BUILDINGNUMBER\": 13,\n",
    "    \"B-CITY\": 49,\n",
    "    \"B-COMPANYNAME\": 83,\n",
    "    \"B-COUNTY\": 31,\n",
    "    \"B-CREDITCARDCVV\": 104,\n",
    "    \"B-CREDITCARDISSUER\": 53,\n",
    "    \"B-CREDITCARDNUMBER\": 54,\n",
    "    \"B-CURRENCY\": 80,\n",
    "    \"B-CURRENCYCODE\": 66,\n",
    "    \"B-CURRENCYNAME\": 85,\n",
    "    \"B-CURRENCYSYMBOL\": 68,\n",
    "    \"B-DATE\": 45,\n",
    "    \"B-DOB\": 19,\n",
    "    \"B-EMAIL\": 32,\n",
    "    \"B-ETHEREUMADDRESS\": 102,\n",
    "    \"B-EYECOLOR\": 38,\n",
    "    \"B-FIRSTNAME\": 4,\n",
    "    \"B-GENDER\": 9,\n",
    "    \"B-HEIGHT\": 11,\n",
    "    \"B-IBAN\": 81,\n",
    "    \"B-IP\": 96,\n",
    "    \"B-IPV4\": 43,\n",
    "    \"B-IPV6\": 21,\n",
    "    \"B-JOBAREA\": 3,\n",
    "    \"B-JOBTITLE\": 29,\n",
    "    \"B-JOBTYPE\": 64,\n",
    "    \"B-LASTNAME\": 40,\n",
    "    \"B-LITECOINADDRESS\": 74,\n",
    "    \"B-MAC\": 78,\n",
    "    \"B-MASKEDNUMBER\": 15,\n",
    "    \"B-MIDDLENAME\": 57,\n",
    "    \"B-NEARBYGPSCOORDINATE\": 23,\n",
    "    \"B-ORDINALDIRECTION\": 62,\n",
    "    \"B-PASSWORD\": 17,\n",
    "    \"B-PHONEIMEI\": 1,\n",
    "    \"B-PHONENUMBER\": 76,\n",
    "    \"B-PIN\": 36,\n",
    "    \"B-PREFIX\": 51,\n",
    "    \"B-SECONDARYADDRESS\": 98,\n",
    "    \"B-SEX\": 63,\n",
    "    \"B-SSN\": 90,\n",
    "    \"B-STATE\": 58,\n",
    "    \"B-STREET\": 47,\n",
    "    \"B-TIME\": 27,\n",
    "    \"B-URL\": 94,\n",
    "    \"B-USERAGENT\": 25,\n",
    "    \"B-USERNAME\": 100,\n",
    "    \"B-VEHICLEVIN\": 6,\n",
    "    \"B-VEHICLEVRM\": 60,\n",
    "    \"B-ZIPCODE\": 88,\n",
    "    \"I-ACCOUNTNAME\": 71,\n",
    "    \"I-ACCOUNTNUMBER\": 35,\n",
    "    \"I-AGE\": 107,\n",
    "    \"I-AMOUNT\": 69,\n",
    "    \"I-BIC\": 110,\n",
    "    \"I-BITCOINADDRESS\": 73,\n",
    "    \"I-BUILDINGNUMBER\": 14,\n",
    "    \"I-CITY\": 50,\n",
    "    \"I-COMPANYNAME\": 84,\n",
    "    \"I-COUNTY\": 106,\n",
    "    \"I-CREDITCARDCVV\": 105,\n",
    "    \"I-CREDITCARDISSUER\": 56,\n",
    "    \"I-CREDITCARDNUMBER\": 55,\n",
    "    \"I-CURRENCY\": 93,\n",
    "    \"I-CURRENCYCODE\": 67,\n",
    "    \"I-CURRENCYNAME\": 86,\n",
    "    \"I-CURRENCYSYMBOL\": 87,\n",
    "    \"I-DATE\": 46,\n",
    "    \"I-DOB\": 20,\n",
    "    \"I-EMAIL\": 33,\n",
    "    \"I-ETHEREUMADDRESS\": 103,\n",
    "    \"I-EYECOLOR\": 39,\n",
    "    \"I-FIRSTNAME\": 5,\n",
    "    \"I-GENDER\": 10,\n",
    "    \"I-HEIGHT\": 12,\n",
    "    \"I-IBAN\": 82,\n",
    "    \"I-IP\": 97,\n",
    "    \"I-IPV4\": 44,\n",
    "    \"I-IPV6\": 22,\n",
    "    \"I-JOBAREA\": 42,\n",
    "    \"I-JOBTITLE\": 30,\n",
    "    \"I-JOBTYPE\": 65,\n",
    "    \"I-LASTNAME\": 41,\n",
    "    \"I-LITECOINADDRESS\": 75,\n",
    "    \"I-MAC\": 79,\n",
    "    \"I-MASKEDNUMBER\": 16,\n",
    "    \"I-MIDDLENAME\": 108,\n",
    "    \"I-NEARBYGPSCOORDINATE\": 24,\n",
    "    \"I-PASSWORD\": 18,\n",
    "    \"I-PHONEIMEI\": 2,\n",
    "    \"I-PHONENUMBER\": 77,\n",
    "    \"I-PIN\": 37,\n",
    "    \"I-PREFIX\": 52,\n",
    "    \"I-SECONDARYADDRESS\": 99,\n",
    "    \"I-SSN\": 91,\n",
    "    \"I-STATE\": 59,\n",
    "    \"I-STREET\": 48,\n",
    "    \"I-TIME\": 28,\n",
    "    \"I-URL\": 95,\n",
    "    \"I-USERAGENT\": 26,\n",
    "    \"I-USERNAME\": 101,\n",
    "    \"I-VEHICLEVIN\": 7,\n",
    "    \"I-VEHICLEVRM\": 61,\n",
    "    \"I-ZIPCODE\": 89,\n",
    "    \"O\": 0\n",
    "  },"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "from peft import PeftConfig, PeftModelForTokenClassification, get_peft_model, PeftMixedModel\n",
    "from adapters import AutoAdapterModel\n",
    "import adapters.composition as ac "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_en = \"Isotonic/ai4privacy_v2_adapter_en\"\n",
    "peft_it = \"Isotonic/ai4privacy_v2_adapter_it\"\n",
    "peft_config_en = PeftConfig.from_pretrained(peft_en)\n",
    "peft_config_it = PeftConfig.from_pretrained(peft_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config_en.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config_en.bias = 'none'\n",
    "peft_config_it.bias = 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_name_or_path = \"distilbert-base-multilingual-cased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "base_model = AutoModelForTokenClassification.from_pretrained(base_model_name_or_path, id2label=id2label, label2id=label2id, num_labels=len(id2label))\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model = PeftMixedModel.from_pretrained(base_model, model_id=peft_en, config=peft_config_en, adapter_name=\"lora_en\", id2label=id2label, label2id=label2id, num_labels=len(id2label)).eval()\n",
    "peft_model.merge_and_unload()\n",
    "# output = peft_model.add_adapter(adapter_name=\"lora_it\", peft_config=peft_config_it)\n",
    "peft_model.set_adapter([\"lora_en\"])\n",
    "# peft_model.set_adapter([\"lora_en\", \"lora_it\"])  # activate both adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lora_en']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_model.active_adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"My name is Sarah and I live in Berkeley, California.\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = peft_model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logits = peft_model(**inputs).logits\n",
    "\n",
    "tokens = inputs.tokens()\n",
    "predictions = torch.argmax(logits, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('[CLS]', 'O')\n",
      "('My', 'O')\n",
      "('name', 'O')\n",
      "('is', 'O')\n",
      "('Sarah', 'O')\n",
      "('and', 'O')\n",
      "('I', 'O')\n",
      "('live', 'O')\n",
      "('in', 'O')\n",
      "('Berkeley', 'O')\n",
      "(',', 'O')\n",
      "('California', 'O')\n",
      "('.', 'O')\n",
      "('[SEP]', 'O')\n"
     ]
    }
   ],
   "source": [
    "for token, prediction in zip(tokens, predictions[0].numpy()):\n",
    "    print((token, id2label[str(prediction)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def analyze_sentence(sentence):\n",
    "  tokens = sentence.split()\n",
    "  inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "  outputs = peft_model(**inputs)\n",
    "\n",
    "  # Post-process NER output en\n",
    "  # ner_labels_map = base_model.get_labels_dict(peft_model_en)\n",
    "  ner_label_ids = torch.argmax(outputs[0], dim=2).numpy().squeeze().tolist()\n",
    "  annotated = []\n",
    "  for token, label_id in zip(tokens, outputs[0]):\n",
    "    token = token.replace('\\u0120', '')\n",
    "    label = id2label[label_id]\n",
    "    annotated.append(f\"{token}<{label}>\" if label != \"O\" else token)\n",
    "  print(\"NER EN: \" + \" \".join(annotated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_sentence(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import get_peft_model\n",
    "\n",
    "model_en = get_peft_model(base_model, peft_config_en, mixed=True, adapter_name=\"peft_en\")\n",
    "model_it = get_peft_model(base_model, peft_config_it, mixed=True, adapter_name=\"peft_it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_en = model_en.merge_and_unload()\n",
    "model_it = model_it.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_en.load_adapter(peft_it, adapter_name=\"peft_it\")\n",
    "model_en.set_adapter([\"peft_en\", \"peft_it\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_model = PeftModelForTokenClassification.from_pretrained(base_model, peft_en, id2label=id2label, label2id=label2id, num_labels=len(id2label), config=peft_config_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftMixedModel\n",
    "\n",
    "base_model = ...  # load the base model, e.g. from transformers\n",
    "# load first adapter, which will be called \"default\"\n",
    "peft_model = PeftMixedModel.from_pretrained(base_model_name_or_path, peft_en, id2label=id2label, label2id=label2id, num_labels=len(id2label), config=peft_config_en)\n",
    "peft_model.load_adapter(peft_it, adapter_name=\"peft_it\", id2label=id2label, label2id=label2id, num_labels=len(id2label), config=peft_config_it)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model.set_adapter([\"default\", \"other\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import safetensors\n",
    "# import torch\n",
    "\n",
    "# pt_state_dict = safetensors.torch.load_file(\"/Users/sripaadsrinivasan/Projects/ai4privacy/notebooks/ai4p_adapter_en/adapter_model.safetensors\", device=\"cpu\")\n",
    "# torch.save(pt_state_dict, \"/Users/sripaadsrinivasan/Projects/ai4privacy/notebooks/ai4p_adapter_en/pytorch_adapter.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adapters import AutoAdapterModel\n",
    "import adapters.composition as ac\n",
    "\n",
    "\n",
    "base_model = AutoAdapterModel.from_pretrained(base_model_name_or_path, id2label=id2label, label2id=label2id, num_labels=len(id2label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import adapters\n",
    "\n",
    "adapters.init(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config_en.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from adapters import AdapterSetup, AutoAdapterModel, LoRAConfig\n",
    "# import adapters.composition as ac\n",
    "\n",
    "# model = AutoAdapterModel.from_pretrained(base_model_name_or_path, num_labels=len(id2label), id2label=id2label)\n",
    "\n",
    "# qc = model.load_adapter(peft_model_en)\n",
    "# sent = model.load_adapter(peft_model_it)\n",
    "\n",
    "# with AdapterSetup(ac.Parallel([qc, sent])):\n",
    "#     print(model(**tokenizer(\"What is AdapterHub?\", return_tensors=\"pt\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from adapters import LoRAConfig\n",
    "\n",
    "# config = LoRAConfig(architecture = \"lora\", r=320, alpha=384, attn_matrices=[\"q_lin\",\"k_lin\",\"v_lin\", \"out_lin\"])\n",
    "# base_model.load_adapter(adapter_name_or_path=\"/Users/sripaadsrinivasan/Projects/ai4privacy/notebooks/ai4p_adapter_en/pytorch_adapter.bin\", config=config, num_labels=len(id2label), id2label=id2label, label2id=label2id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"My name is Sarah and I live in Berkeley, California.\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = base_model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label =  {\n",
    "    0: \"O\",\n",
    "    1: \"B-PHONEIMEI\",\n",
    "    2: \"I-PHONEIMEI\",\n",
    "    3: \"B-JOBAREA\",\n",
    "    4: \"B-FIRSTNAME\",\n",
    "    5: \"I-FIRSTNAME\",\n",
    "    6: \"B-VEHICLEVIN\",\n",
    "    7: \"I-VEHICLEVIN\",\n",
    "    8: \"B-AGE\",\n",
    "    9: \"B-GENDER\",\n",
    "    10: \"I-GENDER\",\n",
    "    11: \"B-HEIGHT\",\n",
    "    12: \"I-HEIGHT\",\n",
    "    13: \"B-BUILDINGNUMBER\",\n",
    "    14: \"I-BUILDINGNUMBER\",\n",
    "    15: \"B-MASKEDNUMBER\",\n",
    "    16: \"I-MASKEDNUMBER\",\n",
    "    17: \"B-PASSWORD\",\n",
    "    18: \"I-PASSWORD\",\n",
    "    19: \"B-DOB\",\n",
    "    20: \"I-DOB\",\n",
    "    21: \"B-IPV6\",\n",
    "    22: \"I-IPV6\",\n",
    "    23: \"B-NEARBYGPSCOORDINATE\",\n",
    "    24: \"I-NEARBYGPSCOORDINATE\",\n",
    "    25: \"B-USERAGENT\",\n",
    "    26: \"I-USERAGENT\",\n",
    "    27: \"B-TIME\",\n",
    "    28: \"I-TIME\",\n",
    "    29: \"B-JOBTITLE\",\n",
    "    30: \"I-JOBTITLE\",\n",
    "    31: \"B-COUNTY\",\n",
    "    32: \"B-EMAIL\",\n",
    "    33: \"I-EMAIL\",\n",
    "    34: \"B-ACCOUNTNUMBER\",\n",
    "    35: \"I-ACCOUNTNUMBER\",\n",
    "    36: \"B-PIN\",\n",
    "    37: \"I-PIN\",\n",
    "    38: \"B-EYECOLOR\",\n",
    "    39: \"I-EYECOLOR\",\n",
    "    40: \"B-LASTNAME\",\n",
    "    41: \"I-LASTNAME\",\n",
    "    42: \"I-JOBAREA\",\n",
    "    43: \"B-IPV4\",\n",
    "    44: \"I-IPV4\",\n",
    "    45: \"B-DATE\",\n",
    "    46: \"I-DATE\",\n",
    "    47: \"B-STREET\",\n",
    "    48: \"I-STREET\",\n",
    "    49: \"B-CITY\",\n",
    "    50: \"I-CITY\",\n",
    "    51: \"B-PREFIX\",\n",
    "    52: \"I-PREFIX\",\n",
    "    53: \"B-CREDITCARDISSUER\",\n",
    "    54: \"B-CREDITCARDNUMBER\",\n",
    "    55: \"I-CREDITCARDNUMBER\",\n",
    "    56: \"I-CREDITCARDISSUER\",\n",
    "    57: \"B-MIDDLENAME\",\n",
    "    58: \"B-STATE\",\n",
    "    59: \"I-STATE\",\n",
    "    60: \"B-VEHICLEVRM\",\n",
    "    61: \"I-VEHICLEVRM\",\n",
    "    62: \"B-ORDINALDIRECTION\",\n",
    "    63: \"B-SEX\",\n",
    "    64: \"B-JOBTYPE\",\n",
    "    65: \"I-JOBTYPE\",\n",
    "    66: \"B-CURRENCYCODE\",\n",
    "    67: \"I-CURRENCYCODE\",\n",
    "    68: \"B-CURRENCYSYMBOL\",\n",
    "    69: \"I-AMOUNT\",\n",
    "    70: \"B-ACCOUNTNAME\",\n",
    "    71: \"I-ACCOUNTNAME\",\n",
    "    72: \"B-BITCOINADDRESS\",\n",
    "    73: \"I-BITCOINADDRESS\",\n",
    "    74: \"B-LITECOINADDRESS\",\n",
    "    75: \"I-LITECOINADDRESS\",\n",
    "    76: \"B-PHONENUMBER\",\n",
    "    77: \"I-PHONENUMBER\",\n",
    "    78: \"B-MAC\",\n",
    "    79: \"I-MAC\",\n",
    "    80: \"B-CURRENCY\",\n",
    "    81: \"B-IBAN\",\n",
    "    82: \"I-IBAN\",\n",
    "    83: \"B-COMPANYNAME\",\n",
    "    84: \"I-COMPANYNAME\",\n",
    "    85: \"B-CURRENCYNAME\",\n",
    "    86: \"I-CURRENCYNAME\",\n",
    "    87: \"I-CURRENCYSYMBOL\",\n",
    "    88: \"B-ZIPCODE\",\n",
    "    89: \"I-ZIPCODE\",\n",
    "    90: \"B-SSN\",\n",
    "    91: \"I-SSN\",\n",
    "    92: \"B-AMOUNT\",\n",
    "    93: \"I-CURRENCY\",\n",
    "    94: \"B-URL\",\n",
    "    95: \"I-URL\",\n",
    "    96: \"B-IP\",\n",
    "    97: \"I-IP\",\n",
    "    98: \"B-SECONDARYADDRESS\",\n",
    "    99: \"I-SECONDARYADDRESS\",\n",
    "    100: \"B-USERNAME\",\n",
    "    101: \"I-USERNAME\",\n",
    "    102: \"B-ETHEREUMADDRESS\",\n",
    "    103: \"I-ETHEREUMADDRESS\",\n",
    "    104: \"B-CREDITCARDCVV\",\n",
    "    105: \"I-CREDITCARDCVV\",\n",
    "    106: \"I-COUNTY\",\n",
    "    107: \"I-AGE\",\n",
    "    108: \"I-MIDDLENAME\",\n",
    "    109: \"B-BIC\",\n",
    "    110: \"I-BIC\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def analyze_sentence(sentence):\n",
    "  tokens = tokenizer.tokenize(sentence)\n",
    "  inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "  outputs = base_model(**inputs)\n",
    "\n",
    "  # Post-process NER output en\n",
    "  # ner_labels_map = base_model.get_labels_dict(peft_model_en)\n",
    "  ner_label_ids = torch.argmax(outputs[0], dim=2).numpy().squeeze().tolist()\n",
    "  ner_labels = [id2label[id_] for id_ in ner_label_ids]\n",
    "  annotated = []\n",
    "  for token, label_id in zip(tokens, ner_label_ids):\n",
    "    token = token.replace('\\u0120', '')\n",
    "    label = id2label[label_id]\n",
    "    annotated.append(f\"{token}<{label}>\" if label != \"O\" else token)\n",
    "  print(\"NER EN: \" + \" \".join(annotated))\n",
    "\n",
    "  # Post-process NER output it\n",
    "  # ner_labels_map = base_model.get_labels_dict(peft_model_it)\n",
    "  ner_label_ids = torch.argmax(outputs[1], dim=2).numpy().squeeze().tolist()\n",
    "  ner_labels = [id2label[id_] for id_ in ner_label_ids]\n",
    "  annotated = []\n",
    "  for token, label_id in zip(tokens, ner_label_ids):\n",
    "    token = token.replace('\\u0120', '')\n",
    "    label = id2label[label_id]\n",
    "    annotated.append(f\"{token}<{label}>\" if label != \"O\" else token)\n",
    "  print(\"NER IT: \" + \" \".join(annotated))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "  \"A man in central Germany tried to leave his house by the front door only to find a brick wall there.\",\n",
    "  \"Il Met Office ha emesso un'allerta meteo gialla per ghiaccio su gran parte del Galles.\",\n",
    "  \"A vibrant animation telling stories of indigenous Australia will be projected on to the Sydney Opera House every night at sunset.\",\n",
    "  \"Ogni sera, al tramonto, sulla Sydney Opera House verr√† proiettata una vivace animazione che racconta le storie degli indigeni australiani.\"\n",
    "]\n",
    "\n",
    "for sentence in sentences:\n",
    "  analyze_sentence(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_model = AutoAdapterModel.from_pretrained(base_model_name_or_path, num_labels=len(id2label), id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_model = AutoModelForTokenClassification.from_pretrained(\n",
    "    base_model_name_or_path, num_labels=len(id2label), id2label=id2label, label2id=label2id\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name_or_path, token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, TaskType \n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.TOKEN_CLS, inference_mode=False, r=320, lora_alpha=384, lora_dropout=0.1, bias=\"all\",\n",
    "    target_modules=[\"q_lin\",\"k_lin\",\"v_lin\", \"out_lin\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# architecture = \"lora\"\n",
    "# selfattn_lora = True\n",
    "# intermediate_lora = False\n",
    "# output_lora = False\n",
    "# r = 320\n",
    "# alpha = 384\n",
    "# attn_matrices = =[\"q_lin\",\"k_lin\",\"v_lin\", \"out_lin\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adapters import LoRAConfig\n",
    "\n",
    "config = LoRAConfig(architecture = \"lora\", r=320, alpha=384, attn_matrices=[\"q_lin\",\"k_lin\",\"v_lin\", \"out_lin\"], )\n",
    "ad_model.add_adapter(\"lora_adapter\", config=config, model=inference_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_list(input_list):\n",
    "    \"\"\"Splits a list into sublists based on non-zero integers, preserving their positions.\n",
    "\n",
    "    Args:\n",
    "        input_list: The input list containing integers.\n",
    "\n",
    "    Returns:\n",
    "        A list of sublists, where each sublist contains a non-zero integer at its original position and zeros elsewhere.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Count the number of non-zero integers:\n",
    "    num_non_zeros = sum(x != 0 for x in input_list)\n",
    "\n",
    "    # 2. Initialize sublists with the original list size, filled with zeros:\n",
    "    sublists = [ [0] * len(input_list) for _ in range(num_non_zeros) ]\n",
    "\n",
    "    # 3. Iterate through the input list and populate sublists:\n",
    "    sublist_index = 0\n",
    "    for i, value in enumerate(input_list):\n",
    "        if value != 0:\n",
    "            sublists[sublist_index][i] = value\n",
    "            sublist_index += 1\n",
    "            if i+1 != 0:\n",
    "                sublists[sublist_index][i] = value\n",
    "                sublist_index += 1\n",
    "\n",
    "    return sublists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [0, 3, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "sublists = split_list(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sublists[0]), len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(set([x.replace(\"B-\",\"\").replace(\"I-\", \"\") for x in list(id2label.values())]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"labels.txt\", \"w\") as f:\n",
    "  for label in labels:\n",
    "    f.write(label + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# architecture: Optional[str] = \"lora\"\n",
    "\n",
    "# selfattn_lora: bool = True\n",
    "# intermediate_lora: bool = False\n",
    "# output_lora: bool = False\n",
    "# leave_out: List[int] = field(default_factory=list)\n",
    "# r: int = 8\n",
    "# alpha: int = 8\n",
    "# dropout: float = 0.0\n",
    "# attn_matrices: List[str] = field(default_factory=lambda: [\"q\", \"v\"])\n",
    "# composition_mode: str = \"add\"\n",
    "# init_weights: str = \"lora\"\n",
    "# use_gating: bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_config = {\n",
    "  \"config\": {\n",
    "    \"adapter_residual_before_ln\": False,\n",
    "    \"cross_adapter\": False,\n",
    "    \"inv_adapter\": None,\n",
    "    \"inv_adapter_reduction_factor\": None,\n",
    "    \"leave_out\": [],\n",
    "    \"ln_after\": False,\n",
    "    \"ln_before\": False,\n",
    "    \"mh_adapter\": False,\n",
    "    \"non_linearity\": \"relu\",\n",
    "    \"original_ln_after\": True,\n",
    "    \"original_ln_before\": True,\n",
    "    \"output_adapter\": True,\n",
    "    \"reduction_factor\": 320,\n",
    "    \"residual_before_ln\": True,\n",
    "    \"architecture\":\n",
    "  },\n",
    "  \"hidden_size\": 768,\n",
    "  \"model_class\": \"BertModelWithHeads\",\n",
    "  \"model_name\": \"bert-base-uncased\",\n",
    "  \"model_type\": \"bert\",\n",
    "  \"name\": \"conll2003_ner\"\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
